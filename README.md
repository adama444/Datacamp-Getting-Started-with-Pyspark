# Datacamp-Getting-Started-with-Pyspark

## Why Pyspark ?

You need to learn a framework that allows you to manipulate datasets on top of a distributed processing  system, as most data-driven organizations will require you to do so. PySpark is a great place to get started, since its syntax is simple and can be picked up easily if you are already familiar with Python. it can handle larger amounts of data than frameworks like pandas.

## Purpose of the project

Using pyspark to execute an end-to-end customer segmentation project.

By the end of this tutorial, you will be familiar with the following concepts:

- Reading csv files with PySpark
- Exploratory Data Analysis with PySpark
- Grouping and sorting data
- Performing arithmetic operations
- Aggregating datasets
- Data Pre-Processing with PySpark
- Working with datetime values
- Type conversion
- Joining two dataframes
- The rank() function
- PySpark Machine Learning
- Creating a feature vector
- Standardizing data
- Building a K-Means clustering model
- Interpreting the model

